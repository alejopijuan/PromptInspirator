{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjK4t1SWMozTRYMxcaf/qD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "80d8dd07ce94466f8fa1d2c37a244fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd8349c33d404716abb311e043d00da3",
              "IPY_MODEL_2166b4162e18450a80ebc4a66d6adef1",
              "IPY_MODEL_dbbde74b24034e58bf2a352b9ef97fe2",
              "IPY_MODEL_28c48264650c4acc87ffcbd1e0758a7a",
              "IPY_MODEL_c067947681a244018f6f0a2af37f45be"
            ],
            "layout": "IPY_MODEL_f57cea6c2a2740028ff51e8e36215a59"
          }
        },
        "dd8349c33d404716abb311e043d00da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_664b74e2dc204fe3a9cdf33bdb25a119",
            "placeholder": "​",
            "style": "IPY_MODEL_73cac2acacfa43a187b60c0e04d102fa",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "2166b4162e18450a80ebc4a66d6adef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_cf5b31082afc4cf4bb4aa2466c8400c2",
            "placeholder": "​",
            "style": "IPY_MODEL_f0bcb535184148eb86070e82c8b864d6",
            "value": ""
          }
        },
        "dbbde74b24034e58bf2a352b9ef97fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_fd1739ab527a49cd8ea67ae45d8556e5",
            "style": "IPY_MODEL_b0de938c913e416eb7e6a91bfea56de3",
            "value": true
          }
        },
        "28c48264650c4acc87ffcbd1e0758a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f04a4daa11204225ba994f329a7f7c13",
            "style": "IPY_MODEL_72e327307b3f4e9185448479479090e5",
            "tooltip": ""
          }
        },
        "c067947681a244018f6f0a2af37f45be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d02ef1c42e7e43a48cf083d162a6ab15",
            "placeholder": "​",
            "style": "IPY_MODEL_473a92a068854c6c8662cf80f7dde620",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "f57cea6c2a2740028ff51e8e36215a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "664b74e2dc204fe3a9cdf33bdb25a119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73cac2acacfa43a187b60c0e04d102fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf5b31082afc4cf4bb4aa2466c8400c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0bcb535184148eb86070e82c8b864d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd1739ab527a49cd8ea67ae45d8556e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0de938c913e416eb7e6a91bfea56de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f04a4daa11204225ba994f329a7f7c13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72e327307b3f4e9185448479479090e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d02ef1c42e7e43a48cf083d162a6ab15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "473a92a068854c6c8662cf80f7dde620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alejopijuan/PromptInspirator/blob/main/Prompt_Inspirator_2_input_POS_position_insert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try 2"
      ],
      "metadata": {
        "id": "k-wOGMW-h9vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade transformers diffusers ftfy;"
      ],
      "metadata": {
        "id": "dPEK0YnhgtM4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d223ef3-5ea1-4148-ec9d-ab062070f38f"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n",
        "#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"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303,
          "referenced_widgets": [
            "80d8dd07ce94466f8fa1d2c37a244fa0",
            "dd8349c33d404716abb311e043d00da3",
            "2166b4162e18450a80ebc4a66d6adef1",
            "dbbde74b24034e58bf2a352b9ef97fe2",
            "28c48264650c4acc87ffcbd1e0758a7a",
            "c067947681a244018f6f0a2af37f45be",
            "f57cea6c2a2740028ff51e8e36215a59",
            "664b74e2dc204fe3a9cdf33bdb25a119",
            "73cac2acacfa43a187b60c0e04d102fa",
            "cf5b31082afc4cf4bb4aa2466c8400c2",
            "f0bcb535184148eb86070e82c8b864d6",
            "fd1739ab527a49cd8ea67ae45d8556e5",
            "b0de938c913e416eb7e6a91bfea56de3",
            "f04a4daa11204225ba994f329a7f7c13",
            "72e327307b3f4e9185448479479090e5",
            "d02ef1c42e7e43a48cf083d162a6ab15",
            "473a92a068854c6c8662cf80f7dde620"
          ]
        },
        "id": "fJvxYs-sguMz",
        "outputId": "976dfa07-9dcc-4a62-81bd-6875a9088bd4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80d8dd07ce94466f8fa1d2c37a244fa0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "from transformers import logging\n",
        "from diffusers import AutoencoderKL, UNet2DConditionModel, LMSDiscreteScheduler\n",
        "from tqdm.auto import tqdm\n",
        "from tqdm.auto import tqdm\n",
        "from torch import autocast\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy\n",
        "from torchvision import transforms as tfms\n",
        "\n",
        "# For video display:\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode"
      ],
      "metadata": {
        "id": "t8p1k8qRgxry"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supress some unnecessary warnings when loading the CLIPTextModel\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "# Set device\n",
        "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "p0uadtJ1iCuN"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uhcG98aMiaYH",
        "outputId": "594ff48e-2b03-499c-b523-ae39913ab2d6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC6J9-YMk6kE",
        "outputId": "fdddc3ff-ed6c-4237-ada9-fe9eb801ed3d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (21.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import accelerate"
      ],
      "metadata": {
        "id": "Fna9dFqZnTbS"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the autoencoder model which will be used to decode the latents into image space. \n",
        "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\")\n"
      ],
      "metadata": {
        "id": "cpNkuqLcihcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a871ecc-af3f-47ba-ead9-b410fe887b39"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
            "```\n",
            "pip install accelerate\n",
            "```\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer and text encoder to tokenize and encode the text. \n",
        "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n"
      ],
      "metadata": {
        "id": "dp6TpUMQjpSJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The UNet model for generating the latents.\n",
        "unet = UNet2DConditionModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "c7IaNQlxjquA",
        "outputId": "4919fd62-adfa-4dde-a4b9-e6667529df39"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
            "```\n",
            "pip install accelerate\n",
            "```\n",
            ".\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-86134732a5de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# The UNet model for generating the latents.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0munet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet2DConditionModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CompVis/stable-diffusion-v1-4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/diffusers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m             )\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m             model, missing_keys, unexpected_keys, mismatched_keys, error_msgs = cls._load_pretrained_model(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/diffusers/modeling_utils.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \"\"\"\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'data/{key}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UntypedStorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untyped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;31m# TODO: Once we decide to break serialization FC, we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0;31m# stop wrapping with _TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The noise scheduler\n",
        "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
        "\n"
      ],
      "metadata": {
        "id": "sznv-J-BlVUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To the GPU we go!\n",
        "vae = vae.to(torch_device)\n",
        "text_encoder = text_encoder.to(torch_device)\n",
        "unet = unet.to(torch_device);"
      ],
      "metadata": {
        "id": "3wW_qVculgRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvWpR_K7ljKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some settings\n",
        "prompt = [\"A watercolor painting of a cute tardigrade\"]\n",
        "height = 512                        # default height of Stable Diffusion\n",
        "width = 512                         # default width of Stable Diffusion\n",
        "num_inference_steps = 50            # Number of denoising steps\n",
        "guidance_scale = 7.5                # Scale for classifier-free guidance\n",
        "generator = torch.manual_seed(32)   # Seed generator to create the inital latent noise\n",
        "batch_size = 1\n",
        "\n",
        "# Prep text \n",
        "text_input = tokenizer(prompt, padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]\n",
        "max_length = text_input.input_ids.shape[-1]\n",
        "uncond_input = tokenizer(\n",
        "    [\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\"\n",
        ")\n",
        "with torch.no_grad():\n",
        "    uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0] \n",
        "text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
        "\n",
        "# Prep Scheduler\n",
        "scheduler.set_timesteps(num_inference_steps)\n",
        "# Prep latents\n",
        "latents = torch.randn(\n",
        "  (batch_size, unet.in_channels, height // 8, width // 8),\n",
        "  generator=generator,\n",
        ")\n",
        "latents = latents.to(torch_device)\n",
        "latents = latents * scheduler.init_noise_sigma # Scaling (previous versions did latents = latents * self.scheduler.sigmas[0]\n",
        "\n",
        "# Loop\n",
        "with autocast(\"cuda\"):\n",
        "    for i, t in tqdm(enumerate(scheduler.timesteps)):\n",
        "        # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
        "        latent_model_input = torch.cat([latents] * 2)\n",
        "        sigma = scheduler.sigmas[i]\n",
        "        # Scale the latents (preconditioning):\n",
        "        # latent_model_input = latent_model_input / ((sigma**2 + 1) ** 0.5) # Diffusers 0.3 and below\n",
        "        latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n",
        "\n",
        "        # predict the noise residual\n",
        "        with torch.no_grad():\n",
        "            noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n",
        "\n",
        "        # perform guidance\n",
        "        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "        noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "        # compute the previous noisy sample x_t -> x_t-1\n",
        "        # latents = scheduler.step(noise_pred, i, latents)[\"prev_sample\"] # Diffusers 0.3 and below\n",
        "        latents = scheduler.step(noise_pred, t, latents).prev_sample\n",
        "\n",
        "# scale and decode the image latents with vae\n",
        "latents = 1 / 0.18215 * latents\n",
        "with torch.no_grad():\n",
        "    image = vae.decode(latents).sample\n",
        "\n",
        "# Display\n",
        "image = (image / 2 + 0.5).clamp(0, 1)\n",
        "image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
        "images = (image * 255).round().astype(\"uint8\")\n",
        "pil_images = [Image.fromarray(image) for image in images]\n",
        "pil_images[0]"
      ],
      "metadata": {
        "id": "EFcaYpXKmV6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rjZoRj4cnd4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_inspirator(prompt = [\"A watercolor painting of a cute tardigrade\"]):\n",
        "      # Some settings\n",
        "  #prompt = [\"A watercolor painting of a cute tardigrade\"]\n",
        "  height = 512                        # default height of Stable Diffusion\n",
        "  width = 512                         # default width of Stable Diffusion\n",
        "  num_inference_steps = 50            # Number of denoising steps\n",
        "  guidance_scale = 7.5                # Scale for classifier-free guidance\n",
        "  generator = torch.manual_seed(32)   # Seed generator to create the inital latent noise\n",
        "  batch_size = 1\n",
        "\n",
        "  # Prep text \n",
        "  text_input = tokenizer(prompt, padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n",
        "  with torch.no_grad():\n",
        "      text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]\n",
        "  max_length = text_input.input_ids.shape[-1]\n",
        "  uncond_input = tokenizer(\n",
        "      [\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\"\n",
        "  )\n",
        "  with torch.no_grad():\n",
        "      uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0] \n",
        "  text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
        "\n",
        "  # Prep Scheduler\n",
        "  scheduler.set_timesteps(num_inference_steps)\n",
        "  # Prep latents\n",
        "  latents = torch.randn(\n",
        "    (batch_size, unet.in_channels, height // 8, width // 8),\n",
        "    generator=generator,\n",
        "  )\n",
        "  latents = latents.to(torch_device)\n",
        "  latents = latents * scheduler.init_noise_sigma # Scaling (previous versions did latents = latents * self.scheduler.sigmas[0]\n",
        "\n",
        "  # Loop\n",
        "  with autocast(\"cuda\"):\n",
        "      for i, t in tqdm(enumerate(scheduler.timesteps)):\n",
        "          # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
        "          latent_model_input = torch.cat([latents] * 2)\n",
        "          sigma = scheduler.sigmas[i]\n",
        "          # Scale the latents (preconditioning):\n",
        "          # latent_model_input = latent_model_input / ((sigma**2 + 1) ** 0.5) # Diffusers 0.3 and below\n",
        "          latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n",
        "\n",
        "          # predict the noise residual\n",
        "          with torch.no_grad():\n",
        "              noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n",
        "\n",
        "          # perform guidance\n",
        "          noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "          noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "          # compute the previous noisy sample x_t -> x_t-1\n",
        "          # latents = scheduler.step(noise_pred, i, latents)[\"prev_sample\"] # Diffusers 0.3 and below\n",
        "          latents = scheduler.step(noise_pred, t, latents).prev_sample\n",
        "\n",
        "  # scale and decode the image latents with vae\n",
        "  latents = 1 / 0.18215 * latents\n",
        "  with torch.no_grad():\n",
        "      image = vae.decode(latents).sample\n",
        "\n",
        "  # Display\n",
        "  image = (image / 2 + 0.5).clamp(0, 1)\n",
        "  image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
        "  images = (image * 255).round().astype(\"uint8\")\n",
        "  pil_images = [Image.fromarray(image) for image in images]\n",
        "  return pil_images[0]"
      ],
      "metadata": {
        "id": "CRXGL0gko11K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seed=0\n",
        "prompt_inspirator([\"A watercolor painting of a cute tardigrade\"])"
      ],
      "metadata": {
        "id": "yz7oal1opNAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AsWRo2De0L3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seed=32\n",
        "prompt_inspirator([\"a size comparison between a tardigrade and a \"])"
      ],
      "metadata": {
        "id": "CkCZEvc30xDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nov 23\n",
        "## User Input"
      ],
      "metadata": {
        "id": "iAcl8q_m1AEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = input()"
      ],
      "metadata": {
        "id": "5EIowSfrl0LP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_inspirator([f\"{user_prompt}\"])"
      ],
      "metadata": {
        "id": "bHI3ckUzmfTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "brlRB-NMmrog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nov 23\n",
        "### Transformers pretrained NER \n",
        "### WRONG USE CASE! \n",
        "## SEARCHING FOR PART OF SPEECH TAGGING"
      ],
      "metadata": {
        "id": "v0xqeH2C-Gf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "example = \"My name is Wolfgang and I live in Berlin\"\n",
        "\n",
        "ner_results = nlp(example)\n",
        "print(ner_results)"
      ],
      "metadata": {
        "id": "7FqFcUYNvsMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = str(input())\n",
        "\n",
        "ner_results = nlp(example)\n",
        "ner_results"
      ],
      "metadata": {
        "id": "s7uPenGJ0L1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_results"
      ],
      "metadata": {
        "id": "6uPIhMOV1U5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NOV 23\n",
        "## PART OF SPEECH TAGGING"
      ],
      "metadata": {
        "id": "N0x9ooLC-WIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bwHDSDN-amZ",
        "outputId": "67970ea3-76f3-4067-9ce9-5ab295cae037"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flair in /usr/local/lib/python3.7/dist-packages (0.11.3)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from flair) (9.0.0)\n",
            "Requirement already satisfied: pptree in /usr/local/lib/python3.7/dist-packages (from flair) (3.1)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in /usr/local/lib/python3.7/dist-packages (from flair) (0.2.7)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.10)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from flair) (1.2.13)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from flair) (2.0.0)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.64.1)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from flair) (6.1.1)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.12.1+cu113)\n",
            "Requirement already satisfied: transformers>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.24.0)\n",
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.7/dist-packages (from flair) (0.5.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2022.6.2)\n",
            "Requirement already satisfied: janome in /usr/local/lib/python3.7/dist-packages (from flair) (0.4.2)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: conllu>=4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.5.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.4.0)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.95)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.9.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from flair) (0.11.0)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from flair) (1.5.11)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.6.5)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (2.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.21.6)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.14.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (1.7.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (1.5.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (0.10.9.7)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (2.6.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.10.1)\n",
            "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (4.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.4.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==4.4.0->flair) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==4.4.0->flair) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==4.4.0->flair) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==4.4.0->flair) (2.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.3)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==4.4.0->flair) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger"
      ],
      "metadata": {
        "id": "9p5_vwd5_7xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# load tagger\n",
        "tagger = SequenceTagger.load(\"flair/pos-english\")\n",
        "\n",
        "original_input = \"Our name is Wolfgang, we are Kings and we love Berlin. I've been to restaurants all over Europe and played with adults.\"\n",
        "# make example sentence\n",
        "sentence = Sentence(original_input)\n",
        "\n",
        "# predict NER tags\n",
        "tagger.predict(sentence)\n",
        "\n",
        "# print sentence\n",
        "print(sentence)\n",
        "\n",
        "# print predicted NER spans\n",
        "print('The following NER tags are found:')\n",
        "# iterate over entities and print\n",
        "for entity in sentence.get_spans('pos'):\n",
        "    print(entity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqufhE5t3XRM",
        "outputId": "f6c27025-8dba-41a0-dc1c-fa53e1bdfa2b"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/huggingface_hub/file_download.py:595: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-23 06:31:55,740 loading file /root/.flair/models/pos-english/a9a73f6cd878edce8a0fa518db76f441f1cc49c2525b2b4557af278ec2f0659e.121306ea62993d04cd1978398b68396931a39eb47754c8a06a87f325ea70ac63\n",
            "2022-11-23 06:31:55,947 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD\n",
            "Sentence: \"Our name is Wolfgang , we are Kings and we love Berlin . I 've been to restaurants all over Europe and played with adults .\" → [\"Our\"/PRP$, \"name\"/NN, \"is\"/VBZ, \"Wolfgang\"/NNP, \",\"/,, \"we\"/PRP, \"are\"/VBP, \"Kings\"/NNPS, \"and\"/CC, \"we\"/PRP, \"love\"/VBP, \"Berlin\"/NNP, \".\"/., \"I\"/PRP, \"'ve\"/VBP, \"been\"/VBN, \"to\"/IN, \"restaurants\"/NNS, \"all\"/RB, \"over\"/IN, \"Europe\"/NNP, \"and\"/CC, \"played\"/VBD, \"with\"/IN, \"adults\"/NNS, \".\"/.]\n",
            "The following NER tags are found:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4nJRxwc-ZFB",
        "outputId": "5da5e17a-c3e3-479f-ecfe-884eb9972abe"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence: \"Our name is Wolfgang , we are Kings and we love Berlin . I 've been to restaurants all over Europe and played with adults .\" → [\"Our\"/PRP$, \"name\"/NN, \"is\"/VBZ, \"Wolfgang\"/NNP, \",\"/,, \"we\"/PRP, \"are\"/VBP, \"Kings\"/NNPS, \"and\"/CC, \"we\"/PRP, \"love\"/VBP, \"Berlin\"/NNP, \".\"/., \"I\"/PRP, \"'ve\"/VBP, \"been\"/VBN, \"to\"/IN, \"restaurants\"/NNS, \"all\"/RB, \"over\"/IN, \"Europe\"/NNP, \"and\"/CC, \"played\"/VBD, \"with\"/IN, \"adults\"/NNS, \".\"/.]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "??sentence"
      ],
      "metadata": {
        "id": "juX6BGXX_sP2"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(sentence);"
      ],
      "metadata": {
        "id": "xnRFnrBjCdVx"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VzzOY5C5_yUu",
        "outputId": "578360c2-a112-4f67-921a-2caa7250bb67"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Our name is Wolfgang , we are Kings and we love Berlin . I 've been to restaurants all over Europe and played with adults .\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(sentence.get_labels())\n",
        "#it's just a list, so I can manipulate and search through it!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGxJIwBkCpD7",
        "outputId": "41c5a531-06e9-4415-ec35-b6bea95ac26d"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__add__',\n",
              " '__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__iadd__',\n",
              " '__imul__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__mul__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__reversed__',\n",
              " '__rmul__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " 'append',\n",
              " 'clear',\n",
              " 'copy',\n",
              " 'count',\n",
              " 'extend',\n",
              " 'index',\n",
              " 'insert',\n",
              " 'pop',\n",
              " 'remove',\n",
              " 'reverse',\n",
              " 'sort']"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence.get_labels()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY4RqRBoDB_I",
        "outputId": "2a8c719c-88ca-4fb4-bd27-41e37524836e"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Token[0]: \"Our\"'/'PRP$' (1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(sentence.get_labels()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F3yhLgqDMvX",
        "outputId": "be47aa94-771c-4e11-b7fc-5fab39d4f39a"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_score',\n",
              " '_value',\n",
              " 'data_point',\n",
              " 'labeled_identifier',\n",
              " 'score',\n",
              " 'set_value',\n",
              " 'shortstring',\n",
              " 'to_dict',\n",
              " 'unlabeled_identifier',\n",
              " 'value']"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence.get_labels()[0].value\n",
        "#string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OVztMkAFDUlm",
        "outputId": "707c7d79-131b-4f14-f0bc-52dd44884db9"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PRP$'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence.get_labels()[7]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTk3lRv_D0wO",
        "outputId": "18470780-ed7b-4b6e-e837-ca79b24c9562"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Token[7]: \"Kings\"'/'NNPS' (0.9722)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence.get_labels()[7].value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xNbbfGykD5Ou",
        "outputId": "d64088a2-34ec-4b06-931d-131573351d87"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NNPS'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "AjEwkO2TDYHG"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.search(\"NN\", sentence.get_labels()[7].value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HApUDwVFDy4f",
        "outputId": "d1f5dca0-0505-4935-c9ab-36a84c055b20"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 2), match='NN'>"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.search(\"NN\", sentence.get_labels()[0].value)"
      ],
      "metadata": {
        "id": "iFZTTZgDEnBx"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label in sentence.get_labels():\n",
        "  match = re.search(\"NN\", label.value)\n",
        "  if match is not None: print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwLGuwhhAQVW",
        "outputId": "f5994e26-0963-4f3b-f66b-903fb40b9328"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token[1]: \"name\" → NN (1.0)\n",
            "Token[3]: \"Wolfgang\" → NNP (0.9999)\n",
            "Token[7]: \"Kings\" → NNPS (0.9722)\n",
            "Token[11]: \"Berlin\" → NNP (0.9999)\n",
            "Token[17]: \"restaurants\" → NNS (1.0)\n",
            "Token[20]: \"Europe\" → NNP (1.0)\n",
            "Token[24]: \"adults\" → NNS (1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(sentence.get_labels()[7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcekKaH8A9FE",
        "outputId": "24e28563-63ca-418c-eeaa-e5e4486d806f"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_score',\n",
              " '_value',\n",
              " 'data_point',\n",
              " 'labeled_identifier',\n",
              " 'score',\n",
              " 'set_value',\n",
              " 'shortstring',\n",
              " 'to_dict',\n",
              " 'unlabeled_identifier',\n",
              " 'value']"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence.get_labels()[7].value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UKgYSXK9B5HK",
        "outputId": "bedc1790-f0a2-40ea-de2f-cd6f7a02d417"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NNPS'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence.get_labels()[7].data_point"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qE1Eyo3HV_W",
        "outputId": "371b849f-4faa-45a2-9151-70ab1acec51b"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Token[7]: \"Kings\" → NNPS (0.9722)"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence.get_labels()[7].labeled_identifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UjZQvmYkHXZg",
        "outputId": "a8d65259-f18a-4d46-d973-74efaa21b104"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Token[7]: \"Kings\"/NNPS'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(sentence.get_labels()[7].labeled_identifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVbOZh6YHkiv",
        "outputId": "b4db4ba0-2999-4de5-87d3-bbb52fe3be49"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.search(\"\\d\", sentence.get_labels()[7].labeled_identifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59dtjT_fH8zO",
        "outputId": "d298ae4e-cee1-463b-dacb-c6e27f53d048"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(6, 7), match='7'>"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(re.search(\"\\d\", sentence.get_labels()[7].labeled_identifier));"
      ],
      "metadata": {
        "id": "XxNeqWQPIKdT"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.search(\"\\d\", sentence.get_labels()[7].labeled_identifier).group()\n",
        "#.group method of re.Match object gives the match."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "U3YgpN_rIPKX",
        "outputId": "fd9ba2dd-6db5-4ad7-ffa6-1b3371521ad9"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsJtG5QFMam8",
        "outputId": "a0d25dc1-f9a3-40e8-c039-24b0b0b48fe7"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_Sentence__remove_zero_width_characters',\n",
              " '_Sentence__restore_windows_1252_characters',\n",
              " '__class__',\n",
              " '__copy__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_embeddings',\n",
              " '_handle_problem_characters',\n",
              " '_known_spans',\n",
              " '_next_sentence',\n",
              " '_position_in_dataset',\n",
              " '_previous_sentence',\n",
              " '_printout_labels',\n",
              " 'add_label',\n",
              " 'add_token',\n",
              " 'annotation_layers',\n",
              " 'clear_embeddings',\n",
              " 'embedding',\n",
              " 'end_pos',\n",
              " 'end_position',\n",
              " 'get_each_embedding',\n",
              " 'get_embedding',\n",
              " 'get_label',\n",
              " 'get_labels',\n",
              " 'get_language_code',\n",
              " 'get_relations',\n",
              " 'get_span',\n",
              " 'get_spans',\n",
              " 'get_token',\n",
              " 'has_label',\n",
              " 'infer_space_after',\n",
              " 'is_context_set',\n",
              " 'is_document_boundary',\n",
              " 'labels',\n",
              " 'language_code',\n",
              " 'left_context',\n",
              " 'next_sentence',\n",
              " 'previous_sentence',\n",
              " 'remove_labels',\n",
              " 'right_context',\n",
              " 'score',\n",
              " 'set_embedding',\n",
              " 'set_label',\n",
              " 'start_pos',\n",
              " 'start_position',\n",
              " 'tag',\n",
              " 'text',\n",
              " 'to',\n",
              " 'to_dict',\n",
              " 'to_original_text',\n",
              " 'to_plain_string',\n",
              " 'to_tagged_string',\n",
              " 'to_tokenized_string',\n",
              " 'tokenized',\n",
              " 'tokens',\n",
              " 'unlabeled_identifier']"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence.get_token(8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRszKCv9MmVh",
        "outputId": "41ad5a41-6d48-4bd6-ea80-232cc2ace2b3"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Token[7]: \"Kings\" → NNPS (0.9722)"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nov 23\n",
        "## Identifying positioning of noun in the sentence"
      ],
      "metadata": {
        "id": "dqF9fNwSJZTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nouns = []\n",
        "for label in sentence.get_labels():\n",
        "  match = re.search(\"NN\", label.value)\n",
        "  position = re.search(\"\\d+\", label.labeled_identifier).group()\n",
        "\n",
        "  #get raw string for the matched noun\n",
        "  raw_word = sentence.text.split()[int(position)] #re.search('\"\\w+\"', str(label)).group()[1:-1], \n",
        "\n",
        "  if match is not None: \n",
        "    print(label)\n",
        "    print(match)\n",
        "    print(position)\n",
        "    nouns.append( (\n",
        "                  #sentence.get_token(int(position)+1), \n",
        "                   raw_word, \n",
        "                   position ) )\n",
        "print(nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sBwtAtdIYN_",
        "outputId": "20de145e-d004-4404-e29d-a924394c9733"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token[1]: \"name\" → NN (1.0)\n",
            "<re.Match object; span=(0, 2), match='NN'>\n",
            "1\n",
            "Token[3]: \"Wolfgang\" → NNP (0.9999)\n",
            "<re.Match object; span=(0, 2), match='NN'>\n",
            "3\n",
            "Token[7]: \"Kings\" → NNPS (0.9722)\n",
            "<re.Match object; span=(0, 2), match='NN'>\n",
            "7\n",
            "Token[11]: \"Berlin\" → NNP (0.9999)\n",
            "<re.Match object; span=(0, 2), match='NN'>\n",
            "11\n",
            "Token[17]: \"restaurants\" → NNS (1.0)\n",
            "<re.Match object; span=(0, 2), match='NN'>\n",
            "17\n",
            "Token[20]: \"Europe\" → NNP (1.0)\n",
            "<re.Match object; span=(0, 2), match='NN'>\n",
            "20\n",
            "Token[24]: \"adults\" → NNS (1.0)\n",
            "<re.Match object; span=(0, 2), match='NN'>\n",
            "24\n",
            "[('name', '1'), ('Wolfgang', '3'), ('Kings', '7'), ('Berlin', '11'), ('restaurants', '17'), ('Europe', '20'), ('adults', '24')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence.text\n",
        "#string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "k9sdReD2JCuA",
        "outputId": "73d58b76-d78f-40a8-cf3f-81314f01c295"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Our name is Wolfgang , we are Kings and we love Berlin . I 've been to restaurants all over Europe and played with adults .\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nouns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOd3Bl-CJ_XD",
        "outputId": "01a1e3e9-7baa-4efd-b591-eab021c1c448"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('name', '1'),\n",
              " ('Wolfgang', '3'),\n",
              " ('Kings', '7'),\n",
              " ('Berlin', '11'),\n",
              " ('restaurants', '17'),\n",
              " ('Europe', '20'),\n",
              " ('adults', '24')]"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_sentence = sentence.text.split()#[int(position)]\n",
        "print(list_sentence)\n",
        "print(' '.join(list_sentence))\n",
        "\n",
        "adjective = \"beautiful\"\n",
        "adjective = input()\n",
        "\n",
        "list_sentence.insert(11, adjective)\n",
        "print(f\"\\nNew adjective {adjective} in position {11}\")\n",
        "print(list_sentence)\n",
        "print(' '.join(list_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v35zR5xAPlu0",
        "outputId": "a071a258-0e5d-4f03-ff5e-516cad10ecf8"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Our', 'name', 'is', 'Wolfgang', ',', 'we', 'are', 'Kings', 'and', 'we', 'love', 'Berlin', '.', 'I', \"'ve\", 'been', 'to', 'restaurants', 'all', 'over', 'Europe', 'and', 'played', 'with', 'adults', '.']\n",
            "Our name is Wolfgang , we are Kings and we love Berlin . I 've been to restaurants all over Europe and played with adults .\n",
            "nfo\n",
            "\n",
            "New adjective nfo in position 11\n",
            "['Our', 'name', 'is', 'Wolfgang', ',', 'we', 'are', 'Kings', 'and', 'we', 'love', 'nfo', 'Berlin', '.', 'I', \"'ve\", 'been', 'to', 'restaurants', 'all', 'over', 'Europe', 'and', 'played', 'with', 'adults', '.']\n",
            "Our name is Wolfgang , we are Kings and we love nfo Berlin . I 've been to restaurants all over Europe and played with adults .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q4-UnzdMQeWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T_pu_WJQR_bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nov 23\n",
        "# BERT implementation with Mask for Bidirectional Contextual prediction"
      ],
      "metadata": {
        "id": "f4K5CrVNTIE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "import string\n",
        "from transformers import BertTokenizer, BertForMaskedLM, XLNetTokenizer, XLNetModel, AutoModelWithLMHead, AutoTokenizer, top_k_top_p_filtering, logging\n",
        "logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "_dkBgCyOTMvw"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_words_to_be_predicted = globals()\n",
        "select_model = globals()\n",
        "enter_input_text = globals()"
      ],
      "metadata": {
        "id": "bUQleTZdYTjL"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_model_config(**kwargs):\n",
        "  for key, value in kwargs.items():\n",
        "    print(\"{0} = {1}\".format(key, value))\n",
        "  \n",
        "  no_words_to_be_predicted = list(kwargs.values())[0] # integer values\n",
        "  select_model = list(kwargs.values())[1] # possible values = 'bert' or 'gpt' or 'xlnet'\n",
        "  enter_input_text = list(kwargs.values())[2] #only string\n",
        "\n",
        "  return no_words_to_be_predicted, select_model, enter_input_text"
      ],
      "metadata": {
        "id": "hulUhgdAYXXi"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_model_config(no_words_to_be_predicted=5, select_model = \"bert\", enter_input_text = \"why are\"):\n",
        "  #no_words_to_be_predicted = list(input(\"integer values: \"))\n",
        "  #select_model = [input(\"'bert' or 'gpt' or 'xlnet': \")] #list.extend([input(\"possible values = 'bert' or 'gpt' or 'xlnet': \")])\n",
        "  #enter_input_text = [input(\"only string: \")]\n",
        "\n",
        "  return no_words_to_be_predicted, select_model, enter_input_text\n",
        "\n",
        "set_model_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqVdLt6jZECM",
        "outputId": "208f9f1f-8767-4200-fe8e-254bf48fd5ff"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 'bert', 'why are')"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name):\n",
        "  try:\n",
        "    if model_name.lower() == \"bert\":\n",
        "      bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "      bert_model = BertForMaskedLM.from_pretrained('bert-base-uncased').eval()\n",
        "      return bert_tokenizer,bert_model\n",
        "    elif model_name.lower() == \"gpt\":\n",
        "      gpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "      gpt_model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
        "      return gpt_tokenizer,gpt_model\n",
        "    else:\n",
        "      xlnet_tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "      xlnet_model = AutoModelWithLMHead.from_pretrained(\"xlnet-base-cased\")\n",
        "      return xlnet_tokenizer, xlnet_model\n",
        "  except Exception as e:\n",
        "    pass"
      ],
      "metadata": {
        "id": "OsGBokJnYod2"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bert encode\n",
        "def encode_bert(tokenizer, text_sentence, add_special_tokens=True):\n",
        "  text_sentence = text_sentence.replace('<mask>', tokenizer.mask_token)\n",
        "  # if <mask> is the last token, append a \".\" so that models dont predict punctuation.\n",
        "  if tokenizer.mask_token == text_sentence.split()[-1]:\n",
        "    text_sentence += ' .'\n",
        "    input_ids = torch.tensor([tokenizer.encode(text_sentence, add_special_tokens=add_special_tokens)])\n",
        "    mask_idx = torch.where(input_ids == tokenizer.mask_token_id)[1].tolist()[0]\n",
        "  return input_ids, mask_idx\n",
        "  \n",
        "# bert decode\n",
        "def decode_bert(tokenizer, pred_idx, top_clean):\n",
        "  ignore_tokens = string.punctuation + '[PAD]'\n",
        "  tokens = []\n",
        "  for w in pred_idx:\n",
        "    token = ''.join(tokenizer.decode(w).split())\n",
        "    if token not in ignore_tokens:\n",
        "      tokens.append(token.replace('##', ''))\n",
        "  return '\\n'.join(tokens[:top_clean])"
      ],
      "metadata": {
        "id": "02Y7yka5bpWI"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_predictions(text_sentence,  model_name, top_clean=5):\n",
        "  if model_name.lower() == \"bert\":\n",
        "    # ========================= BERT =================================\n",
        "    input_ids, mask_idx = encode_bert(bert_tokenizer, text_sentence)\n",
        "    with torch.no_grad():\n",
        "      predict = bert_model(input_ids)[0]\n",
        "    bert = decode_bert(bert_tokenizer, predict[0, mask_idx, :].topk(no_words_to_be_predicted).indices.tolist(), top_clean)\n",
        "    return {'bert': bert}\n",
        "\n",
        "  elif model_name.lower() == \"gpt\":\n",
        "    # ========================= GPT =================================\n",
        "    input_ids = encode_gpt(gpt_tokenizer, text_sentence)\n",
        "    with torch.no_grad():\n",
        "      predict = gpt_model(input_ids)[0][:, -1, :]\n",
        "    gpt = decode_gpt(gpt_tokenizer, input_ids, predict, top_clean)\n",
        "    return {'gpt': gpt}"
      ],
      "metadata": {
        "id": "wCB1GVEKfMna"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction_end_of_sentence(input_text, model_name):\n",
        "  try:\n",
        "    if model_name.lower() == \"bert\":\n",
        "      input_text += ' <mask>'\n",
        "      print(input_text)\n",
        "      res = get_all_predictions(input_text, model_name, top_clean=int(no_words_to_be_predicted)) \n",
        "      return res\n",
        "    elif model_name.lower() == \"gpt\":\n",
        "      print(input_text)\n",
        "      res = get_all_predictions(input_text, model_name, top_clean=int(no_words_to_be_predicted)) \n",
        "      return res\n",
        "    else:\n",
        "      print(input_text)\n",
        "      res = get_all_predictions(input_text, model_name, top_clean=int(no_words_to_be_predicted))\n",
        "      return res\n",
        "\n",
        "  except Exception as error:\n",
        "    print(error)"
      ],
      "metadata": {
        "id": "4tvB5eXSbsKd"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  print(\"Next Word Prediction with Pytorch using BERT, GPT, and XLNet\")\n",
        "  no_words_to_be_predicted, select_model, enter_input_text = set_model_config(no_words_to_be_predicted=1, select_model = \"bert\", enter_input_text = \"why are all\")\n",
        "  if select_model.lower() == \"bert\":\n",
        "    bert_tokenizer, bert_model  = load_model(select_model)\n",
        "    res = get_prediction_end_of_sentence(enter_input_text, select_model)\n",
        "    print(\"result is: {}\" .format(res))\n",
        "    answer_bert = []\n",
        "    print(res['bert'].split(\"\\n\"))\n",
        "    for i in res['bert'].split(\"\\n\"):\n",
        "      answer_bert.append(i)\n",
        "      answer_as_string_bert = \"    \".join(answer_bert)\n",
        "      print(\"output answer is: {}\" .format(answer_as_string_bert))\n",
        "except Exception as e:\n",
        "  print('Some problem occured'), print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bITLx1fb7-Y",
        "outputId": "d8f3e815-79c2-43a9-a2c9-5343a19599cf"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next Word Prediction with Pytorch using BERT, GPT, and XLNet\n",
            "why are all <mask>\n",
            "result is: {'bert': 'you'}\n",
            "['you']\n",
            "output answer is: you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8f_bAcrIcIFb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}